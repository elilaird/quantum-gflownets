{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-b07882b7b3a0>:2: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  import importlib, pkg_resources\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'pkg_resources' from '/lustre/work/client/users/ejlaird/.conda/envs/quantum/lib/python3.9/site-packages/pkg_resources/__init__.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update package resources to account for version changes.\n",
    "import importlib, pkg_resources\n",
    "importlib.reload(pkg_resources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_quantum as tfq\n",
    "\n",
    "import gym, cirq, sympy\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from collections import deque, defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from cirq.contrib.svg import SVGCircuit\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_qubit_rotation(qubit, symbols):\n",
    "    \"\"\"\n",
    "    Returns Cirq gates that apply a rotation of the bloch sphere about the X,\n",
    "    Y and Z axis, specified by the values in `symbols`.\n",
    "    \"\"\"\n",
    "    return [cirq.rx(symbols[0])(qubit),\n",
    "            cirq.ry(symbols[1])(qubit),\n",
    "            cirq.rz(symbols[2])(qubit)]\n",
    "\n",
    "def entangling_layer(qubits):\n",
    "    \"\"\"\n",
    "    Returns a layer of CZ entangling gates on `qubits` (arranged in a circular topology).\n",
    "    \"\"\"\n",
    "    cz_ops = [cirq.CZ(q0, q1) for q0, q1 in zip(qubits, qubits[1:])]\n",
    "    cz_ops += ([cirq.CZ(qubits[0], qubits[-1])] if len(qubits) != 2 else [])\n",
    "    return cz_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_circuit(qubits, n_layers):\n",
    "    \"\"\"Prepares a data re-uploading circuit on `qubits` with `n_layers` layers.\"\"\"\n",
    "    # Number of qubits\n",
    "    n_qubits = len(qubits)\n",
    "\n",
    "    # Sympy symbols for variational angles\n",
    "    params = sympy.symbols(f'theta(0:{3*(n_layers+1)*n_qubits})')\n",
    "    params = np.asarray(params).reshape((n_layers + 1, n_qubits, 3))\n",
    "\n",
    "    # Sympy symbols for encoding angles\n",
    "    inputs = sympy.symbols(f'x(0:{n_layers})'+f'_(0:{n_qubits})')\n",
    "    inputs = np.asarray(inputs).reshape((n_layers, n_qubits))\n",
    "\n",
    "    # Define circuit\n",
    "    circuit = cirq.Circuit()\n",
    "    for l in range(n_layers):\n",
    "        # Variational layer\n",
    "        circuit += cirq.Circuit(one_qubit_rotation(q, params[l, i]) for i, q in enumerate(qubits))\n",
    "        circuit += entangling_layer(qubits)\n",
    "        # Encoding layer\n",
    "        circuit += cirq.Circuit(cirq.rx(inputs[l, i])(q) for i, q in enumerate(qubits))\n",
    "\n",
    "    # Last varitional layer\n",
    "    circuit += cirq.Circuit(one_qubit_rotation(q, params[n_layers, i]) for i,q in enumerate(qubits))\n",
    "\n",
    "    return circuit, list(params.flat), list(inputs.flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"1016.1524609375002\" height=\"150.0\"><line x1=\"34.7588671875\" x2=\"986.1524609375002\" y1=\"25.0\" y2=\"25.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"34.7588671875\" x2=\"986.1524609375002\" y1=\"75.0\" y2=\"75.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"34.7588671875\" x2=\"986.1524609375002\" y1=\"125.0\" y2=\"125.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"404.74449218750004\" x2=\"404.74449218750004\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"464.74449218750004\" x2=\"464.74449218750004\" y1=\"75.0\" y2=\"125.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"524.7444921875001\" x2=\"524.7444921875001\" y1=\"25.0\" y2=\"125.0\" stroke=\"black\" stroke-width=\"3\" /><rect x=\"10.0\" y=\"5.0\" width=\"49.517734375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"34.7588671875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 0): </text><rect x=\"10.0\" y=\"55.0\" width=\"49.517734375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"34.7588671875\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 1): </text><rect x=\"10.0\" y=\"105.0\" width=\"49.517734375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"34.7588671875\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 2): </text><rect x=\"79.517734375\" y=\"5.0\" width=\"82.31109375000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"120.67328125\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(theta0)</text><rect x=\"79.517734375\" y=\"55.0\" width=\"82.31109375000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"120.67328125\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(theta3)</text><rect x=\"79.517734375\" y=\"105.0\" width=\"82.31109375000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"120.67328125\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(theta6)</text><rect x=\"181.82882812500003\" y=\"5.0\" width=\"81.54109375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"222.59937500000004\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(theta1)</text><rect x=\"181.82882812500003\" y=\"55.0\" width=\"81.54109375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"222.59937500000004\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(theta4)</text><rect x=\"181.82882812500003\" y=\"105.0\" width=\"81.54109375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"222.59937500000004\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(theta7)</text><rect x=\"283.36992187500005\" y=\"5.0\" width=\"81.37457031250001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"324.0572070312501\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(theta2)</text><rect x=\"283.36992187500005\" y=\"55.0\" width=\"81.37457031250001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"324.0572070312501\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(theta5)</text><rect x=\"283.36992187500005\" y=\"105.0\" width=\"81.37457031250001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"324.0572070312501\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(theta8)</text><circle cx=\"404.74449218750004\" cy=\"25.0\" r=\"10.0\" /><circle cx=\"404.74449218750004\" cy=\"75.0\" r=\"10.0\" /><circle cx=\"464.74449218750004\" cy=\"75.0\" r=\"10.0\" /><circle cx=\"464.74449218750004\" cy=\"125.0\" r=\"10.0\" /><circle cx=\"524.7444921875001\" cy=\"25.0\" r=\"10.0\" /><circle cx=\"524.7444921875001\" cy=\"125.0\" r=\"10.0\" /><rect x=\"564.7444921875001\" y=\"5.0\" width=\"69.45953125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"599.4742578125001\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(x0_0)</text><rect x=\"564.7444921875001\" y=\"55.0\" width=\"69.45953125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"599.4742578125001\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(x0_1)</text><rect x=\"564.7444921875001\" y=\"105.0\" width=\"69.45953125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"599.4742578125001\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(x0_2)</text><rect x=\"654.2040234375002\" y=\"5.0\" width=\"91.21832031250001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"699.8131835937502\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(theta9)</text><rect x=\"654.2040234375002\" y=\"55.0\" width=\"91.21832031250001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"699.8131835937502\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(theta12)</text><rect x=\"654.2040234375002\" y=\"105.0\" width=\"91.21832031250001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"699.8131835937502\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(theta15)</text><rect x=\"765.4223437500002\" y=\"5.0\" width=\"90.4483203125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"810.6465039062502\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(theta10)</text><rect x=\"765.4223437500002\" y=\"55.0\" width=\"90.4483203125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"810.6465039062502\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(theta13)</text><rect x=\"765.4223437500002\" y=\"105.0\" width=\"90.4483203125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"810.6465039062502\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(theta16)</text><rect x=\"875.8706640625002\" y=\"5.0\" width=\"90.28179687500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"921.0115625000002\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(theta11)</text><rect x=\"875.8706640625002\" y=\"55.0\" width=\"90.28179687500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"921.0115625000002\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(theta14)</text><rect x=\"875.8706640625002\" y=\"105.0\" width=\"90.28179687500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"921.0115625000002\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(theta17)</text></svg>"
      ],
      "text/plain": [
       "<cirq.contrib.svg.svg.SVGCircuit at 0x15555106ce80>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_qubits, n_layers = 3, 1\n",
    "qubits = cirq.GridQubit.rect(1, n_qubits)\n",
    "circuit, _, _ = generate_circuit(qubits, n_layers)\n",
    "SVGCircuit(circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReUploadingPQC(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Performs the transformation (s_1, ..., s_d) -> (theta_1, ..., theta_N, lmbd[1][1]s_1, ..., lmbd[1][M]s_1,\n",
    "        ......., lmbd[d][1]s_d, ..., lmbd[d][M]s_d) for d=input_dim, N=theta_dim and M=n_layers.\n",
    "    An activation function from tf.keras.activations, specified by `activation` ('linear' by default) is\n",
    "        then applied to all lmbd[i][j]s_i.\n",
    "    All angles are finally permuted to follow the alphabetical order of their symbol names, as processed\n",
    "        by the ControlledPQC.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, qubits, n_layers, observables, activation=\"linear\", name=\"re-uploading_PQC\"):\n",
    "        super(ReUploadingPQC, self).__init__(name=name)\n",
    "        self.n_layers = n_layers\n",
    "        self.n_qubits = len(qubits)\n",
    "\n",
    "        circuit, theta_symbols, input_symbols = generate_circuit(qubits, n_layers)\n",
    "\n",
    "        theta_init = tf.random_uniform_initializer(minval=0.0, maxval=np.pi)\n",
    "        self.theta = tf.Variable(\n",
    "            initial_value=theta_init(shape=(1, len(theta_symbols)), dtype=\"float32\"),\n",
    "            trainable=True, name=\"thetas\"\n",
    "        )\n",
    "\n",
    "        lmbd_init = tf.ones(shape=(self.n_qubits * self.n_layers,))\n",
    "        self.lmbd = tf.Variable(\n",
    "            initial_value=lmbd_init, dtype=\"float32\", trainable=True, name=\"lambdas\"\n",
    "        )\n",
    "\n",
    "        # Define explicit symbol order.\n",
    "        symbols = [str(symb) for symb in theta_symbols + input_symbols]\n",
    "        self.indices = tf.constant([symbols.index(a) for a in sorted(symbols)])\n",
    "\n",
    "        self.activation = activation\n",
    "        self.empty_circuit = tfq.convert_to_tensor([cirq.Circuit()])\n",
    "        self.computation_layer = tfq.layers.ControlledPQC(circuit, observables)        \n",
    "\n",
    "    def call(self, inputs):\n",
    "        # inputs[0] = encoding data for the state.\n",
    "        batch_dim = tf.gather(tf.shape(inputs[0]), 0)\n",
    "        tiled_up_circuits = tf.repeat(self.empty_circuit, repeats=batch_dim)\n",
    "        tiled_up_thetas = tf.tile(self.theta, multiples=[batch_dim, 1])\n",
    "        tiled_up_inputs = tf.tile(inputs[0], multiples=[1, self.n_layers])\n",
    "        scaled_inputs = tf.einsum(\"i,ji->ji\", self.lmbd, tiled_up_inputs)\n",
    "        squashed_inputs = tf.keras.layers.Activation(self.activation)(scaled_inputs)\n",
    "\n",
    "        joined_vars = tf.concat([tiled_up_thetas, squashed_inputs], axis=1)\n",
    "        joined_vars = tf.gather(joined_vars, self.indices, axis=1)\n",
    "\n",
    "        return self.computation_layer([tiled_up_circuits, joined_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Alternating(tf.keras.layers.Layer):\n",
    "    def __init__(self, output_dim):\n",
    "        super(Alternating, self).__init__()\n",
    "        self.w = tf.Variable(\n",
    "            initial_value=tf.constant([[(-1.)**i for i in range(output_dim)]]), dtype=\"float32\",\n",
    "            trainable=True, name=\"obs-weights\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qubits = 4 # Dimension of the state vectors in CartPole\n",
    "n_layers = 5 # Number of layers in the PQC\n",
    "n_actions = 2 # Number of actions in CartPole\n",
    "\n",
    "qubits = cirq.GridQubit.rect(1, n_qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ops = [cirq.Z(q) for q in qubits]\n",
    "observables = [reduce((lambda x, y: x * y), ops)] # Z_0*Z_1*Z_2*Z_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_policy(qubits, n_layers, n_actions, beta, observables):\n",
    "    \"\"\"Generates a Keras model for a data re-uploading PQC policy.\"\"\"\n",
    "\n",
    "    input_tensor = tf.keras.Input(shape=(len(qubits), ), dtype=tf.dtypes.float32, name='input')\n",
    "    re_uploading_pqc = ReUploadingPQC(qubits, n_layers, observables)([input_tensor])\n",
    "    process = tf.keras.Sequential([\n",
    "        Alternating(n_actions),\n",
    "        tf.keras.layers.Lambda(lambda x: x * beta),\n",
    "        tf.keras.layers.Softmax()\n",
    "    ], name=\"observables-policy\")\n",
    "    policy = process(re_uploading_pqc)\n",
    "    model = tf.keras.Model(inputs=[input_tensor], outputs=policy)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = generate_model_policy(qubits, n_layers, n_actions, 1.0, observables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True, dpi=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_episodes(state_bounds, n_actions, model, n_episodes, env_name):\n",
    "    \"\"\"Interact with environment in batched fashion.\"\"\"\n",
    "\n",
    "    trajectories = [defaultdict(list) for _ in range(n_episodes)]\n",
    "    envs = [gym.make(env_name) for _ in range(n_episodes)]\n",
    "\n",
    "    done = [False for _ in range(n_episodes)]\n",
    "    states = [e.reset()[0] for e in envs] # added [0] to get rid of the second output of reset()\n",
    "\n",
    "    while not all(done):\n",
    "        unfinished_ids = [i for i in range(n_episodes) if not done[i]]\n",
    "        normalized_states = [s/state_bounds for i, s in enumerate(states) if not done[i]]\n",
    "\n",
    "        for i, state in zip(unfinished_ids, normalized_states):\n",
    "            trajectories[i]['states'].append(state)\n",
    "\n",
    "        # Compute policy for all unfinished envs in parallel\n",
    "        states = tf.convert_to_tensor(normalized_states)\n",
    "        action_probs = model([states])\n",
    "\n",
    "        # Store action and transition all environments to the next state\n",
    "        states = [None for i in range(n_episodes)]\n",
    "        for i, policy in zip(unfinished_ids, action_probs.numpy()):\n",
    "            action = np.random.choice(n_actions, p=policy)\n",
    "            states[i], reward, done[i], _, _ = envs[i].step(action) # added _ to remove last {} in env\n",
    "            trajectories[i]['actions'].append(action)\n",
    "            trajectories[i]['rewards'].append(reward)\n",
    "\n",
    "    return trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_returns(rewards_history, gamma):\n",
    "    \"\"\"Compute discounted returns with discount factor `gamma`.\"\"\"\n",
    "    returns = []\n",
    "    discounted_sum = 0\n",
    "    for r in rewards_history[::-1]:\n",
    "        discounted_sum = r + gamma * discounted_sum\n",
    "        returns.insert(0, discounted_sum)\n",
    "\n",
    "    # Normalize them for faster and more stable learning\n",
    "    returns = np.array(returns)\n",
    "    returns = (returns - np.mean(returns)) / (np.std(returns) + 1e-8)\n",
    "    returns = returns.tolist()\n",
    "\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_bounds = np.array([2.4, 2.5, 0.21, 2.5])\n",
    "gamma = 1\n",
    "batch_size = 10\n",
    "n_episodes = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_in = tf.keras.optimizers.Adam(learning_rate=0.1, amsgrad=True)\n",
    "optimizer_var = tf.keras.optimizers.Adam(learning_rate=0.01, amsgrad=True)\n",
    "optimizer_out = tf.keras.optimizers.Adam(learning_rate=0.1, amsgrad=True)\n",
    "\n",
    "# Assign the model parameters to each optimizer\n",
    "w_in, w_var, w_out = 1, 0, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def reinforce_update(states, actions, returns, model):\n",
    "    states = tf.convert_to_tensor(states)\n",
    "    actions = tf.convert_to_tensor(actions)\n",
    "    returns = tf.convert_to_tensor(returns)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(model.trainable_variables)\n",
    "        logits = model(states)\n",
    "        p_actions = tf.gather_nd(logits, actions)\n",
    "        log_probs = tf.math.log(p_actions)\n",
    "        loss = tf.math.reduce_sum(-log_probs * returns) / batch_size\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    for optimizer, w in zip([optimizer_in, optimizer_var, optimizer_out], [w_in, w_var, w_out]):\n",
    "        optimizer.apply_gradients([(grads[w], model.trainable_variables[w])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lustre/work/client/users/ejlaird/.conda/envs/quantum/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished episode 10 Average rewards:  14.9\n",
      "Finished episode 20 Average rewards:  20.2\n",
      "Finished episode 30 Average rewards:  31.1\n",
      "Finished episode 40 Average rewards:  38.7\n",
      "Finished episode 50 Average rewards:  28.7\n",
      "Finished episode 60 Average rewards:  27.4\n",
      "Finished episode 70 Average rewards:  40.6\n",
      "Finished episode 80 Average rewards:  34.5\n",
      "Finished episode 90 Average rewards:  50.8\n",
      "Finished episode 100 Average rewards:  53.6\n",
      "Finished episode 110 Average rewards:  72.8\n",
      "Finished episode 120 Average rewards:  97.9\n",
      "Finished episode 130 Average rewards:  116.2\n",
      "Finished episode 140 Average rewards:  112.2\n",
      "Finished episode 150 Average rewards:  148.4\n",
      "Finished episode 160 Average rewards:  181.9\n",
      "Finished episode 170 Average rewards:  263.6\n",
      "Finished episode 180 Average rewards:  209.8\n",
      "Finished episode 190 Average rewards:  220.3\n",
      "Finished episode 200 Average rewards:  171.0\n",
      "Finished episode 210 Average rewards:  268.3\n",
      "Finished episode 220 Average rewards:  311.2\n",
      "Finished episode 230 Average rewards:  372.6\n",
      "Finished episode 240 Average rewards:  279.9\n",
      "Finished episode 250 Average rewards:  397.4\n",
      "Finished episode 260 Average rewards:  610.0\n"
     ]
    }
   ],
   "source": [
    "env_name = \"CartPole-v1\"\n",
    "\n",
    "# Start training the agent\n",
    "episode_reward_history = []\n",
    "for batch in range(n_episodes // batch_size):\n",
    "    # Gather episodes\n",
    "    episodes = gather_episodes(state_bounds, n_actions, model, batch_size, env_name)\n",
    "\n",
    "    # Group states, actions and returns in numpy arrays\n",
    "    states = np.concatenate([ep['states'] for ep in episodes])\n",
    "    actions = np.concatenate([ep['actions'] for ep in episodes])\n",
    "    rewards = [ep['rewards'] for ep in episodes]\n",
    "    returns = np.concatenate([compute_returns(ep_rwds, gamma) for ep_rwds in rewards])\n",
    "    returns = np.array(returns, dtype=np.float32)\n",
    "\n",
    "    id_action_pairs = np.array([[i, a] for i, a in enumerate(actions)])\n",
    "\n",
    "    # Update model parameters.\n",
    "    reinforce_update(states, id_action_pairs, returns, model)\n",
    "\n",
    "    # Store collected rewards\n",
    "    for ep_rwds in rewards:\n",
    "        episode_reward_history.append(np.sum(ep_rwds))\n",
    "\n",
    "    avg_rewards = np.mean(episode_reward_history[-10:])\n",
    "\n",
    "    print('Finished episode', (batch + 1) * batch_size,\n",
    "          'Average rewards: ', avg_rewards)\n",
    "\n",
    "    if avg_rewards >= 500.0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
